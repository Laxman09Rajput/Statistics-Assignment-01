{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Statistics Basics\n",
        " 1.  Explain the different types of data (qualitative and quantitative) and provide examples of each. Discuss\n",
        "nominal, ordinal, interval, and ratio scales.\n",
        "\n",
        "  - qualitative and quantitative\n",
        "   Data is generally classified into two main types: qualitative (categorical) and quantitative (numerical). Qualitative data describes characteristics, labels, or qualities that don’t involve numbers, like names, colors, or opinions. For example, if a survey asks people about their favorite color—red, blue, or green—that’s qualitative data.\n",
        "\n",
        "     On the other hand, quantitative data deals with numbers and measurable values. It includes things like height, weight, and temperature. For instance, recording students test scores (75, 85, 90) is an example of quantitative data. Quantitative data is further divided into discrete (countable values, like the number of children in a family) and continuous [measurable values, like a person’s height in centimeters]\n",
        "\n",
        "\n",
        "   Nominal Scale   \n",
        "\n",
        "   The nominal scale is the simplest way to classify qualitative data. It consists of categories or labels without any specific order or ranking. The values in a nominal scale are just different from each other but have no numerical significance. For example, classifying fruits as apple, banana, or mango, identifying a person’s nationality as Indian or American, or recording gender as male or female—all of these are nominal data. Since there’s no logical sequence, you can’t rank or measure them. This type of data is commonly used in surveys, labeling, and classification. Unlike numerical data, nominal values cannot be added, subtracted, or used in mathematical calculations.\n",
        "\n",
        "   Ordinal Scale\n",
        "\n",
        "   When data has a meaningful order or ranking but the variances between the values are not constant or quantifiable, the ordinal scale is employed.  This is frequently observed in grading schemes, ratings, and surveys.  The order makes sense, for instance, when a customer assesses a service as poor, average, good, or exceptional; but, \"good\" and \"excellent\" are not always the same as 'poor' and 'average' In a race, for instance, we know who placed higher if someone finishes first, second, or third, but we are unaware of how much time separated them.  Ordinal data allows us to rank objects, but because the gaps between values aren't consistent, we can't do exact mathematical computations.\n",
        "\n",
        "   Interval Scale\n",
        "\n",
        "   When using the interval scale, which is a numerical measurement, order is important and value differences are consistent and significant.  It does not, however, have a real zero, which means that zero does not signify the whole absence of the characteristic being assessed.  Temperature in degrees Celsius or Fahrenheit is a typical example.  20°C and 30°C differ in the same way as 30°C and 40°C, but 0°C does not imply \"no temperature.\"  Years in a timeline (e.g., 2000, 2010, 2020) provide another example.  Because there isn't a true zero point, multiplication and division are meaningless for interval data, but addition and subtraction are legitimate.\n",
        "\n",
        "\n",
        "   Ratio Scale\n",
        "\n",
        "   The ratio scale, which has all the characteristics of an interval scale but a real zero point—zero denoting the complete absence of the quantity being measured—is the highest degree of measurement.  This enables any mathematical operations, including division and multiplication, to be used in meaningful comparisons.  Income (0 rupees signifies no earnings), height (0 cm means no height), and weight (0 kg means no weight) are a few examples.  People who weigh 80 kg are twice as hefty as those who weigh 40 kg, therefore ratio data is perfect for financial and scientific computations.  This kind of information is the most accurate and frequently utilized in practical applications.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " 2. What are the measures of central tendency, and when should you use each? Discuss the mean, median,\n",
        "and mode with examples and situations where each is appropriate.\n",
        "\n",
        "  - Measures of Central Tendency\n",
        "\n",
        " The center of a dataset can be found with the aid of measures of central tendency.  The mean, median, and mode are the three primary types; each is helpful in a certain circumstance.  A precise analysis is ensured by selecting the appropriate one.  For instance, if there are extreme values in wage data, the median is frequently better than the mean.  These metrics are commonly employed in research, education, and finance.\n",
        "\n",
        " Mean\n",
        "\n",
        " The mean is calculated by dividing the total number of values by their sum.  When data is dispersed uniformly, it functions best.  For instance, the mean is 90 if the test results are 80, 85, 90, 95, and 100.  But if there are outliers, such as in wage statistics where one extremely high salary distorts the average, it can be deceptive\n",
        "\n",
        " Median\n",
        "\n",
        " The middle number in an ordered set of data is called the median.  When data is skewed or contains outliers, it is helpful.  For instance, the median (35K) is a better representation than the mean for wages of 25K, 30K, 35K, 40K, and 2Lakh.  It is frequently applied to exam scores, income, and real estate values where the average is distorted by extreme numbers.\n",
        "\n",
        " Mode\n",
        "\n",
        " The value that occurs the most frequently is the mode.  It is helpful for classifying data or for determining the most frequent occurrence.  For instance, the mode is 9 if the shoe sizes sold are 7, 8, 8, 9, 9, 10, and so on.  It's frequently used to identify popular trends in fashion, market research, and consumer preferences.\n",
        "\n",
        "\n",
        " 3. 3. Explain the concept of dispersion. How do variance and standard deviation measure the spread of data ?\n",
        "\n",
        "  -  Concept of Dispersion\n",
        "\n",
        "  A dataset's dispersion is the degree to which its data points are dispersed or dispersed.  Whether values are widely dispersed or firmly packed around the average is clarified by it.  More variability is indicated by a large dispersion, whereas consistency is shown by a low dispersion.  A class's scores have a low dispersion, for instance, if most of the students have scores near 80, but a significant dispersion occurs if some receive 50 and others 100\n",
        "\n",
        "  Variance and Standard Deviation\n",
        "\n",
        "  Each data point's variance indicates its distance from the mean.  By averaging the squared deviations from the mean, it is computed.  More variation indicates that the data is more dispersed.  On the other hand, standard deviation (its square root) is more useful because it is in the same unit as the data, whereas variance is in squared units.  A high standard deviation, for instance, indicates that students' performance varies greatly.  These metrics are frequently employed in quality control, research, and finance to evaluate consistency and risk.\n",
        "\n",
        "\n",
        "\n",
        "  4. What is a box plot, and what can it tell you about the distribution of data ?\n",
        "\n",
        "   - A box plot, also called a box-and-whisker plot, is a visual depiction of the distribution of a dataset.  By displaying the minimum, first quartile (Q1), median (Q2), third quartile (Q3), and maximum values, it can be used to identify outliers, skewness, and variability.  Although the whiskers extend to the smallest and largest non-outlier values, the box reflects the interquartile range, or middle 50%, of the data.  Outliers are any points that show values that are not typical.  Box plots, for instance, can be used to rapidly determine whether a distribution is right-skewed or if the majority of wages are distributed inside a range.  For rapid insights, it's commonly employed in research, finance, and data analysis..\n",
        "\n",
        "\n",
        " 5.  Discuss the role of random sampling in making inferences about populations.\n",
        "\n",
        "   - The use of random sampling is essential for drawing reliable conclusions about a population without polling every member.  As a result, bias is lessened and the sample is more representative because it guarantees that each person of the population has an equal chance of being chosen.  This enables researchers to extrapolate insights from a smaller subgroup to the entire group.  In an election poll, for instance, surveying a randomly chosen sample of voters can forecast general voting patterns.  Random sampling is frequently used to make data-driven judgments in the social sciences, medical research, and market research.  By enhancing validity and reliability, a well-designed random sample guarantees that findings accurately represent the population's characteristics.\n",
        "\n",
        " 6. Explain the concept of skewness and its types. How does skewness affect the interpretation of data ?\n",
        "\n",
        "  - Skewness describes the asymmetry of a dataset’s distribution. A symmetrical dataset has no skewness, meaning the left and right sides of the distribution are balanced. However, if data is unevenly distributed, it can be positively or negatively skewed. Positive skew (right-skewed) means the tail is longer on the right, with a few high values pulling the mean higher (e.g., income data where most people earn less, but a few earn millions). Negative skew (left-skewed) means the tail is longer on the left, with a few extremely low values dragging the mean down. Skewness affects data interpretation because the mean moves in the direction of the skew, making the median a better measure of central tendency when extreme values are present.\n",
        "\n",
        "  7.  What is the interquartile range (IQR), and how is it used to detect outliers ?\n",
        "\n",
        "   -  The Interquartile Range (IQR) measures the spread of the middle 50% of a dataset, helping us understand data variability while ignoring extreme values. It is calculated as IQR = Q3 - Q1, where Q1 (first quartile) is the 25th percentile and Q3 (third quartile) is the 75th percentile. This means the IQR represents the range between the lower and upper middle sections of the data, making it more reliable than the full range, which can be affected by extreme values.\n",
        "\n",
        "   IQR is also used to detect outliers—values that are unusually high or low compared to the rest of the data. Any value below Q1 - 1.5×IQR or above Q3 + 1.5×IQR is considered an outlier. For example, in test scores, if most students score between 60 and 90, but a few get 20 or 100, those extreme values may be outliers. IQR is widely used in finance, research, and quality control to identify unusual data points and ensure accurate analysis.\n",
        "\n",
        "\n",
        " 8. Discuss the conditions under which the binomial distribution is used.\n",
        "\n",
        "  - When an experiment has two alternative outcomes (success or failure) and is conducted a certain number of times under identical conditions, the binomial distribution is employed.  The results of one experiment have no bearing on the results of the others as each trial is independent.  There is a continual chance of success in each try.  For instance, a binomial distribution is used when a coin is flipped ten times (heads or tails) or when determining if 20 people purchase a product (buy or don't buy).  It is frequently used in survey analysis, medical trials, and quality control to forecast the probability of a specific number of successful trials.\n",
        "\n",
        "  9. Explain the properties of the normal distribution and the empirical rule (68-95-99.7 rule).\n",
        "\n",
        "   - The normal distribution is a bell-shaped, symmetric curve where most values cluster around the mean, with fewer extreme values on either side. It is defined by two parameters: the mean (μ) and standard deviation (σ). The mean, median, and mode are all equal in a perfect normal distribution. Many real-world variables, like height, IQ scores, and exam results, follow this pattern.\n",
        "\n",
        "     The empirical rule (68-95-99.7 rule) helps understand data spread in a normal distribution. It states that 68% of values fall within 1σ, 95% within 2σ, and 99.7% within 3σ of the mean. This rule is useful in statistics, finance, and quality control to identify unusual data points and make predictions.\n",
        "\n",
        "\n",
        " 10.  Provide a real-life example of a Poisson process and calculate the probability for a specific event.\n",
        "\n",
        "  -  Receiving text messages follows a Poisson process because messages arrive randomly but at an average rate per hour. The probability of receiving exactly 7 messages in the next hour is approximately 0.1044 (or 10.44%). This means that in about 10 out of 100 hours, you can expect to get exactly 7 messages. Poisson processes like this are commonly used in call centers, hospital emergencies, and website traffic analysis to predict the likelihood of random events happening in a fixed time period\n",
        "\n",
        " 11.  Explain what a random variable is and differentiate between discrete and continuous random variables.\n",
        "\n",
        "  -  A random variable is a numerical value that represents the outcome of a\n",
        "     random experiment. It assigns numbers to different possible results of a chance-based event. For example, in a dice roll, the outcome (1, 2, 3, 4, 5, or 6) is a random variable because it depends on chance. Random variables are widely used in statistics, probability, and real-life scenarios like predicting weather conditions or stock prices.\n",
        "\n",
        "            There are two types of random variables: discrete and continuous. A discrete random variable takes specific, countable values such as the number of students in a classroom (e.g., 20, 21, 22). It does not take fractional values. In contrast, a continuous random variable can take any value within a range, including decimals, such as a person’s height (e.g., 5.6 feet, 5.75 feet). Continuous variables are measured rather than counted and are common in areas like physics, economics, and medicine.\n",
        "\n",
        "\n",
        "\n",
        " 12.  Provide an example dataset, calculate both covariance and correlation, and interpret the results.\n",
        "\n",
        "   -   Hours Studied: [2, 4, 6, 8, 10]\n",
        "\n",
        "       Test Scores: [50, 60, 70, 80, 90]\n",
        "\n",
        "\n",
        " Covariance\n",
        "\n",
        " Covariance tells us how two things change together. We calculated it as 40.0, which is positive, meaning that as study time increases, test scores also increase.\n",
        "\n",
        " Correlation\n",
        "\n",
        " Correlation measures the strength of this relationship. We got 1.0, which means a perfect positive relationship—more study time always leads to higher scores.\n",
        "\n",
        " Conclusion\n",
        "\n",
        " Covariance shows the direction of the relationship, while correlation shows both direction and strength. Correlation is more useful because it’s easy to compare across different situations.          \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "SXhB-w0eQiyS"
      }
    }
  ]
}